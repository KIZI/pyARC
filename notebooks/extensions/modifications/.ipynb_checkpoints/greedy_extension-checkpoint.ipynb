{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run ../../../main.py\n",
    "\n",
    "import pyarc.qcba as qcba\n",
    "from pyarc import CBA\n",
    "from pyarc.qcba import QCBA\n",
    "from pyarc.qcba.data_structures import *\n",
    "from pyarc.qcba import QuantitativeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyarc.algorithms import M1Algorithm, M2Algorithm, top_rules, createCARs \n",
    "from pyarc.data_structures import TransactionDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyarc.qcba.data_structures import (\n",
    "    IntervalReader,\n",
    "    Interval,\n",
    "    QuantitativeDataFrame,\n",
    "    QuantitativeCAR\n",
    ")\n",
    "\n",
    "interval_reader = IntervalReader()\n",
    "\n",
    "interval_reader.closed_bracket = \"\", \"NULL\"\n",
    "interval_reader.open_bracket = \"NULL\", \"\"\n",
    "interval_reader.infinity_symbol = \"inf\", \"inf\"\n",
    "interval_reader.members_separator = \"_to_\"\n",
    "\n",
    "interval_reader.compile_reader()\n",
    "\n",
    "i = interval_reader.read(\"82.9815_to_inf\")\n",
    "\n",
    "QuantitativeCAR.interval_reader = interval_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying selected transformations\n",
      "refitting\n",
      "literal pruning\n",
      "trimming\n",
      "extending\n",
      "[                                                  ]\n",
      "[############                                      ]\n",
      "[#########################                         ]\n",
      "[#####################################             ]\n",
      "post pruning\n",
      "overlap pruning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[CAR {petalwidth=<0.1;0.6>} => {class=Iris-setosa} sup: 0.33 conf: 1.00 len: 2, id: 153,\n",
       " CAR {petalwidth=<1.8;2.5>,sepallength=<6.0;7.9>} => {class=Iris-virginica} sup: 0.25 conf: 1.00 len: 3, id: 135,\n",
       " CAR {petalwidth=<1.8;2.4>,sepalwidth=<2.5;3.1>} => {class=Iris-virginica} sup: 0.21 conf: 1.00 len: 3, id: 140]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetname = \"iris0\"\n",
    "\n",
    "pd_ds = pd.read_csv(\"c:/code/python/machine_learning/assoc_rules/train/{}.csv\".format(datasetname))\n",
    "    \n",
    "    \n",
    "pd_ds_undiscr = pd.read_csv(\"c:/code/python/machine_learning/assoc_rules/folds_undiscr/train/{}.csv\".format(datasetname))\n",
    "pd_ds_undiscr_test = pd.read_csv(\"c:/code/python/machine_learning/assoc_rules/folds_undiscr/test/{}.csv\".format(datasetname))\n",
    "\n",
    "txns = TransactionDB.from_DataFrame(pd_ds)\n",
    "txns_test = TransactionDB.from_DataFrame(pd.read_csv(\"c:/code/python/machine_learning/assoc_rules/test/{}.csv\".format(datasetname)))\n",
    "\n",
    "\n",
    "rm_cba = CBA()\n",
    "rm_cba.fit(txns)\n",
    "\n",
    "rm_qcba = QCBA(rm_cba, QuantitativeDataFrame(pd_ds_undiscr))\n",
    "qcba_clf = rm_qcba.fit()\n",
    "\n",
    "qcba_clf.rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class RuleExtender1:\n",
    "    \n",
    "    def __init__(self, dataframe, min_conditional_improvement=-0.01, min_improvement=0):\n",
    "    \n",
    "        if type(dataframe) != QuantitativeDataFrame:\n",
    "            raise Exception(\n",
    "                \"type of dataset must be pandas.DataFrame\"\n",
    "            )\n",
    "            \n",
    "        self.__dataframe = dataframe\n",
    "        self.min_conditional_improvement = min_conditional_improvement\n",
    "        self.min_improvement = min_improvement\n",
    "        \n",
    "        \n",
    "    def transform_greedy(self, rules, skip_ahead=1):\n",
    "        \n",
    "        copied_rules = [ rule.copy() for rule in rules ]\n",
    "\n",
    "        progress_bar_len = 50\n",
    "        copied_rules_len = len(copied_rules)\n",
    "        progress_bar = \"#\" * progress_bar_len\n",
    "        progress_bar_empty = \" \" * progress_bar_len\n",
    "        last_progress_bar_idx = -1\n",
    "\n",
    "        extended_rules = []\n",
    "\n",
    "        #print(\"len: \", copied_rules_len)\n",
    "\n",
    "        for i, rule in enumerate(copied_rules):\n",
    "            current_progress_bar_idx = math.floor(i / copied_rules_len * progress_bar_len)\n",
    "            \n",
    "            if last_progress_bar_idx != current_progress_bar_idx:\n",
    "                last_progress_bar_idx = current_progress_bar_idx\n",
    "                \n",
    "                progress_string = \"[\" + progress_bar[:last_progress_bar_idx] + progress_bar_empty[last_progress_bar_idx:] + \"]\"\n",
    "                \n",
    "                print(*progress_string, sep=\"\")\n",
    "\n",
    "            extended_rules.append(self.__extend_greedy(rule, skip_ahead=skip_ahead))\n",
    "        \n",
    "        return extended_rules\n",
    "    \n",
    "    \n",
    "        \n",
    "    def __extend_greedy(self, rule, skip_ahead=1):\n",
    "        ext = self.__extend_rule_greedy(rule, skip_ahead=skip_ahead)\n",
    "        \n",
    "        return ext\n",
    "    \n",
    "    \n",
    "    def __extend_rule_greedy(self, rule, skip_ahead=1):\n",
    "        \n",
    "        \n",
    "        min_improvement=self.min_improvement\n",
    "        min_conditional_improvement=self.min_conditional_improvement\n",
    "        \n",
    "        # check improvemnt argument ranges\n",
    "        \n",
    "        step = 0\n",
    "        \n",
    "        current_best = rule\n",
    "        direct_extensions = self.__get_extensions_greedy(rule)\n",
    "        \n",
    "        current_best.update_properties(self.__dataframe)\n",
    "        \n",
    "        while True:\n",
    "            extension_succesful = False\n",
    "\n",
    "            direct_extensions = self.__get_extensions_greedy(current_best)\n",
    "\n",
    "            #print(\"extending - new cycle\")\n",
    "            \n",
    "            for candidate in direct_extensions:\n",
    "                #print(\"\\tcandidate - direct extensions\")\n",
    "                #print(\"\\t\", direct_extensions)\n",
    "                candidate.update_properties(self.__dataframe)\n",
    "                \n",
    "                delta_confidence = candidate.confidence - current_best.confidence\n",
    "                delta_support = candidate.support - current_best.support\n",
    "                \n",
    "                \n",
    "                if self.__crisp_accept(delta_confidence, delta_support, min_improvement):\n",
    "                    current_best = candidate\n",
    "                    extension_succesful = True\n",
    "                    break\n",
    "                    \n",
    "                \n",
    "                if self.__conditional_accept(delta_confidence, min_conditional_improvement):\n",
    "                    enlargement = candidate\n",
    "                    \n",
    "                    while True:\n",
    "                        enlargement = self.get_beam_extensions_greedy(enlargement, skip_ahead=skip_ahead)\n",
    "                        \n",
    "                        if not enlargement:\n",
    "                            break\n",
    "                            \n",
    "                        candidate.update_properties(self.__dataframe)\n",
    "                        enlargement.update_properties(self.__dataframe)\n",
    "\n",
    "                        delta_confidence = enlargement.confidence - current_best.confidence\n",
    "                        delta_support = enlargement.support - current_best.support\n",
    "\n",
    "                        if self.__crisp_accept(delta_confidence, delta_support, min_improvement):\n",
    "                            current_best = enlargement\n",
    "                            #plotils.plot_quant_rules([current_best])\n",
    "                            #plt.show()\n",
    "                            \n",
    "                            #print(step)\n",
    "                            step += 1\n",
    "                            \n",
    "                            extension_succesful = True\n",
    "                            \n",
    "                        elif self.__conditional_accept(delta_confidence, min_conditional_improvement):\n",
    "                            #plotils.plot_quant_rules([enlargement])\n",
    "                            #plt.show()\n",
    "                            \n",
    "                            #print(step)\n",
    "                            step += 1\n",
    "                            \n",
    "                            continue\n",
    "                        \n",
    "                        else:\n",
    "                            break\n",
    "            \n",
    "            \n",
    "                    if extension_succesful == True:\n",
    "                        break\n",
    "                        \n",
    "\n",
    "                else:\n",
    "                    # continue to next candidate\n",
    "                    continue\n",
    "           \n",
    "        \n",
    "            if extension_succesful == False:\n",
    "                break\n",
    "                    \n",
    "        return current_best\n",
    "    \n",
    "    \n",
    "            \n",
    "    def __get_extensions_greedy(self, rule, skip_ahead=1):\n",
    "        extended_rules = []\n",
    "        \n",
    "        for literal in rule.antecedent:\n",
    "            attribute, interval = literal\n",
    "            \n",
    "            neighborhood = self.__get_direct_extensions_greedy(literal, skip_ahead=skip_ahead)\n",
    "            \n",
    "            for extended_literal in neighborhood:\n",
    "                # copy the rule so the extended literal\n",
    "                # can replace the default literal\n",
    "                copied_rule = rule.copy()\n",
    "                \n",
    "                # find the index of the literal\n",
    "                # so that it can be replaced\n",
    "                current_literal_index = copied_rule.antecedent.index(literal)\n",
    "                \n",
    "                copied_rule.antecedent[current_literal_index] = extended_literal\n",
    "                copied_rule.was_extended = True\n",
    "                copied_rule.extended_literal = extended_literal\n",
    "                \n",
    "                extended_rules.append(copied_rule)\n",
    "\n",
    "        extended_rules.sort(reverse=True)\n",
    "             \n",
    "        return extended_rules\n",
    "        \n",
    "        \n",
    "   \n",
    "    def __get_direct_extensions_greedy(self, literal, skip_ahead=1):\n",
    "        \"\"\"\n",
    "        ensure sort and unique\n",
    "        before calling functions\n",
    "        \"\"\"\n",
    "        \n",
    "        attribute, interval = literal\n",
    "\n",
    "        # if nominal\n",
    "        # needs correction to return null and skip when extending\n",
    "        if type(interval) == str:\n",
    "            return [literal]\n",
    "        \n",
    "        vals = self.__dataframe.column(attribute)\n",
    "        vals_len = vals.size\n",
    "\n",
    "        mask = interval.test_membership(vals)\n",
    "\n",
    "        # indices of interval members\n",
    "        # we want to extend them \n",
    "        # once to the left\n",
    "        # and once to the right\n",
    "        # bu we have to check if resulting\n",
    "        # indices are not larger than value size\n",
    "        member_indexes = np.where(mask)[0]\n",
    "\n",
    "        first_index = member_indexes[0]\n",
    "        last_index = member_indexes[-1]\n",
    "\n",
    "        first_index_modified = first_index - skip_ahead\n",
    "        last_index_modified = last_index + skip_ahead\n",
    "        \n",
    "        no_left_extension = False\n",
    "        no_right_extension = False\n",
    "\n",
    "        if first_index_modified < 0:\n",
    "            no_left_extension = True\n",
    "\n",
    "        # if last_index_modified is larger than\n",
    "        # available indices\n",
    "        if last_index_modified > vals_len - 1:\n",
    "            no_right_extension = True\n",
    "\n",
    "\n",
    "        new_left_bound = interval.minval\n",
    "        new_right_bound = interval.maxval\n",
    "\n",
    "        if not no_left_extension:\n",
    "            new_left_bound = vals[first_index_modified]\n",
    "\n",
    "        if not no_right_extension:\n",
    "            new_right_bound = vals[last_index_modified]\n",
    "\n",
    "\n",
    "        # prepare return values\n",
    "        extensions = []\n",
    "\n",
    "        if not no_left_extension:\n",
    "            # when values are [1, 2, 3, 3, 4, 5]\n",
    "            # and the corresponding interval is (2, 4)\n",
    "            # instead of resulting interval being (1, 4)\n",
    "            \n",
    "            temp_interval = Interval(\n",
    "                new_left_bound,\n",
    "                interval.maxval,\n",
    "                True,\n",
    "                interval.right_inclusive\n",
    "            )\n",
    "\n",
    "            extensions.append((attribute, temp_interval))\n",
    "\n",
    "        if not no_right_extension:\n",
    "\n",
    "            temp_interval = Interval(\n",
    "                interval.minval,\n",
    "                new_right_bound,\n",
    "                interval.left_inclusive,\n",
    "                True\n",
    "            )\n",
    "\n",
    "            extensions.append((attribute, temp_interval))\n",
    "\n",
    "        return extensions\n",
    "        \n",
    "    \n",
    "    # make private\n",
    "    def get_beam_extensions_greedy(self, rule, skip_ahead=1):\n",
    "        if not rule.was_extended:\n",
    "            return None\n",
    "\n",
    "        # literal which extended the rule\n",
    "        literal = rule.extended_literal\n",
    "        \n",
    "        extended_literal = self.__get_direct_extensions_greedy(literal, skip_ahead=skip_ahead)\n",
    "        \n",
    "        if not extended_literal and skip_ahead > 1:\n",
    "            return self.get_beam_extensions_greedy(rule, skip_ahead=1)\n",
    "        elif not extended_literal:\n",
    "            return None\n",
    "        \n",
    "        copied_rule = rule.copy()\n",
    "        \n",
    "        literal_index = copied_rule.antecedent.index(literal)\n",
    "        \n",
    "        # so that literal is not an array\n",
    "        copied_rule.antecedent[literal_index] = extended_literal[0]\n",
    "        copied_rule.was_extended = True\n",
    "        copied_rule.extended_literal = extended_literal[0]\n",
    "        \n",
    "        return copied_rule\n",
    "        \n",
    "    \n",
    "    def __crisp_accept(self, delta_confidence, delta_support, min_improvement):\n",
    "        if delta_confidence >= min_improvement and delta_support > 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def __conditional_accept(self, delta_conf, min_improvement):\n",
    "        if delta_conf >= min_improvement:\n",
    "            return True\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying all transformations\n",
      "[                                                  ]\n",
      "[#                                                 ]\n",
      "[##                                                ]\n",
      "[###                                               ]\n",
      "[####                                              ]\n",
      "[#####                                             ]\n",
      "[######                                            ]\n",
      "[#######                                           ]\n",
      "[########                                          ]\n",
      "[#########                                         ]\n",
      "[##########                                        ]\n",
      "[###########                                       ]\n",
      "[############                                      ]\n",
      "[#############                                     ]\n",
      "[##############                                    ]\n",
      "[###############                                   ]\n",
      "[################                                  ]\n",
      "[#################                                 ]\n",
      "[##################                                ]\n",
      "[###################                               ]\n",
      "[####################                              ]\n",
      "[#####################                             ]\n",
      "[######################                            ]\n",
      "[#######################                           ]\n",
      "[########################                          ]\n",
      "[#########################                         ]\n",
      "[##########################                        ]\n",
      "[###########################                       ]\n",
      "[############################                      ]\n",
      "[#############################                     ]\n",
      "[##############################                    ]\n",
      "[###############################                   ]\n",
      "[################################                  ]\n",
      "[#################################                 ]\n",
      "[##################################                ]\n",
      "[###################################               ]\n",
      "[####################################              ]\n",
      "[#####################################             ]\n",
      "[######################################            ]\n",
      "[#######################################           ]\n",
      "[########################################          ]\n",
      "[#########################################         ]\n",
      "[##########################################        ]\n",
      "[###########################################       ]\n",
      "[############################################      ]\n",
      "[#############################################     ]\n",
      "[##############################################    ]\n",
      "[###############################################   ]\n",
      "[################################################  ]\n",
      "[################################################# ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([CAR {Bare_Nuclei=<9.0;10.0>,Bland_Chromatin=<4;10>} => {Class=malignant} sup: 0.17 conf: 1.00 len: 3, id: 1535,\n",
       "  CAR {Bare_Nuclei=<4.0;10.0>,Cell_Shape_Uniformity=<5;10>,Marginal_Adhesion=<2;10>,Normal_Nucleoli=<3;10>} => {Class=malignant} sup: 0.17 conf: 1.00 len: 5, id: 5905,\n",
       "  CAR {Bare_Nuclei=<4.0;10.0>,Bland_Chromatin=<4;10>,Cell_Shape_Uniformity=<5;10>,Normal_Nucleoli=<3;10>} => {Class=malignant} sup: 0.15 conf: 1.00 len: 5, id: 5959,\n",
       "  CAR {Bare_Nuclei=<4.0;10.0>,Bland_Chromatin=<4;10>,Cell_Size_Uniformity=<5;10>,Normal_Nucleoli=<3;10>} => {Class=malignant} sup: 0.15 conf: 1.00 len: 5, id: 1689,\n",
       "  CAR {Bare_Nuclei=<4.0;10.0>,Bland_Chromatin=<4;10>,Cell_Size_Uniformity=<5;10>,Normal_Nucleoli=<3;10>} => {Class=malignant} sup: 0.15 conf: 1.00 len: 5, id: 5934,\n",
       "  CAR {Cell_Size_Uniformity=<5;10>,Clump_Thickness=<7;10>} => {Class=malignant} sup: 0.15 conf: 1.00 len: 3, id: 7119,\n",
       "  CAR {Bare_Nuclei=<9.0;10.0>,Cell_Shape_Uniformity=<5;10>} => {Class=malignant} sup: 0.15 conf: 1.00 len: 3, id: 1534,\n",
       "  CAR {Bare_Nuclei=<2.0;10.0>,Cell_Shape_Uniformity=<5;10>,Clump_Thickness=<7;10>} => {Class=malignant} sup: 0.15 conf: 1.00 len: 4, id: 7017,\n",
       "  CAR {Cell_Size_Uniformity=<5;10>,Mitoses=<2;10>} => {Class=malignant} sup: 0.12 conf: 1.00 len: 3, id: 5581,\n",
       "  CAR {Bare_Nuclei=<3.0;10.0>,Clump_Thickness=<7;10>,Normal_Nucleoli=<1;7>} => {Class=malignant} sup: 0.12 conf: 1.00 len: 4, id: 7028,\n",
       "  CAR {Cell_Shape_Uniformity=<5;10>,Mitoses=<2;10>} => {Class=malignant} sup: 0.11 conf: 1.00 len: 3, id: 5590,\n",
       "  CAR {Cell_Shape_Uniformity=<5;10>,Clump_Thickness=<7;10>,Single_Epi_Cell_Size=<4;10>} => {Class=malignant} sup: 0.11 conf: 1.00 len: 4, id: 7134,\n",
       "  CAR {Cell_Shape_Uniformity=<5;10>,Clump_Thickness=<7;10>,Marginal_Adhesion=<4;10>} => {Class=malignant} sup: 0.10 conf: 1.00 len: 4, id: 7079,\n",
       "  CAR {Bare_Nuclei=<3.0;10.0>,Clump_Thickness=<7;10>,Mitoses=<1;1>} => {Class=malignant} sup: 0.09 conf: 1.00 len: 4, id: 7029,\n",
       "  CAR {Bare_Nuclei=<7.0;10.0>,Bland_Chromatin=<4;10>,Cell_Size_Uniformity=<1;8>,Mitoses=<1;1>} => {Class=malignant} sup: 0.09 conf: 1.00 len: 5, id: 3146,\n",
       "  CAR {Normal_Nucleoli=<10;10>} => {Class=malignant} sup: 0.09 conf: 1.00 len: 2, id: 2527,\n",
       "  CAR {Bare_Nuclei=<5.0;10.0>,Clump_Thickness=<6;10>,Marginal_Adhesion=<1;4>} => {Class=malignant} sup: 0.09 conf: 1.00 len: 4, id: 7024,\n",
       "  CAR {Bare_Nuclei=<5.0;10.0>,Cell_Shape_Uniformity=<5;10>,Single_Epi_Cell_Size=<2;4>} => {Class=malignant} sup: 0.08 conf: 1.00 len: 4, id: 2686,\n",
       "  CAR {Bare_Nuclei=<8.0;10.0>,Bland_Chromatin=<4;10>,Single_Epi_Cell_Size=<2;4>} => {Class=malignant} sup: 0.08 conf: 1.00 len: 4, id: 7373,\n",
       "  CAR {Bare_Nuclei=<7.0;10.0>,Marginal_Adhesion=<2;10>,Mitoses=<1;1>,Normal_Nucleoli=<3;10>} => {Class=malignant} sup: 0.08 conf: 1.00 len: 5, id: 5912,\n",
       "  CAR {Bare_Nuclei=<7.0;10.0>,Bland_Chromatin=<4;10>,Mitoses=<1;1>,Normal_Nucleoli=<3;10>} => {Class=malignant} sup: 0.08 conf: 1.00 len: 5, id: 5965,\n",
       "  CAR {Cell_Size_Uniformity=<5;10>,Marginal_Adhesion=<2;4>} => {Class=malignant} sup: 0.08 conf: 1.00 len: 3, id: 4806,\n",
       "  CAR {Bare_Nuclei=<6.0;10.0>,Marginal_Adhesion=<2;4>} => {Class=malignant} sup: 0.08 conf: 1.00 len: 3, id: 4791,\n",
       "  CAR {Clump_Thickness=<7;10>,Marginal_Adhesion=<4;10>,Normal_Nucleoli=<1;7>} => {Class=malignant} sup: 0.07 conf: 1.00 len: 4, id: 7085,\n",
       "  CAR {Bland_Chromatin=<2;10>,Clump_Thickness=<7;10>,Mitoses=<1;1>,Single_Epi_Cell_Size=<4;10>} => {Class=malignant} sup: 0.07 conf: 1.00 len: 5, id: 7137,\n",
       "  CAR {Bare_Nuclei=<6.0;10.0>,Bland_Chromatin=<4;10>,Clump_Thickness=<1;5>} => {Class=malignant} sup: 0.07 conf: 1.00 len: 4, id: 7370,\n",
       "  CAR {Bare_Nuclei=<3.0;10.0>,Clump_Thickness=<7;10>,Single_Epi_Cell_Size=<2;3>} => {Class=malignant} sup: 0.06 conf: 1.00 len: 4, id: 7026,\n",
       "  CAR {Clump_Thickness=<7;10>,Marginal_Adhesion=<4;10>,Mitoses=<1;1>} => {Class=malignant} sup: 0.06 conf: 1.00 len: 4, id: 7086,\n",
       "  CAR {Cell_Shape_Uniformity=<5;10>,Marginal_Adhesion=<4;10>,Single_Epi_Cell_Size=<2;4>} => {Class=malignant} sup: 0.06 conf: 1.00 len: 4, id: 2700,\n",
       "  CAR {Bland_Chromatin=<4;10>,Clump_Thickness=<2;7>,Mitoses=<2;10>} => {Class=malignant} sup: 0.06 conf: 1.00 len: 4, id: 5446,\n",
       "  CAR {Bare_Nuclei=<7.0;10.0>,Bland_Chromatin=<4;10>,Cell_Shape_Uniformity=<1;6>,Mitoses=<1;1>} => {Class=malignant} sup: 0.06 conf: 1.00 len: 5, id: 4234,\n",
       "  CAR {Bland_Chromatin=<1;6>,Clump_Thickness=<7;10>,Mitoses=<2;10>} => {Class=malignant} sup: 0.06 conf: 1.00 len: 4, id: 5507,\n",
       "  CAR {Clump_Thickness=<6;10>,Marginal_Adhesion=<1;4>,Mitoses=<2;10>} => {Class=malignant} sup: 0.05 conf: 1.00 len: 4, id: 5515,\n",
       "  CAR {Bare_Nuclei=<7.0;10.0>,Bland_Chromatin=<4;10>,Single_Epi_Cell_Size=<2;3>} => {Class=malignant} sup: 0.05 conf: 1.00 len: 4, id: 2688,\n",
       "  CAR {Clump_Thickness=<7;10>,Marginal_Adhesion=<1;2>,Normal_Nucleoli=<3;10>} => {Class=malignant} sup: 0.04 conf: 1.00 len: 4, id: 5860,\n",
       "  CAR {Bare_Nuclei=<1.0;3.0>,Cell_Size_Uniformity=<5;10>} => {Class=malignant} sup: 0.04 conf: 1.00 len: 3, id: 7591,\n",
       "  CAR {Bland_Chromatin=<4;10>,Marginal_Adhesion=<4;10>,Single_Epi_Cell_Size=<2;3>} => {Class=malignant} sup: 0.04 conf: 1.00 len: 4, id: 2702,\n",
       "  CAR {Bland_Chromatin=<4;10>,Clump_Thickness=<7;10>,Normal_Nucleoli=<1;2>} => {Class=malignant} sup: 0.03 conf: 1.00 len: 4, id: 7167,\n",
       "  CAR {Cell_Shape_Uniformity=<2;4>,Cell_Size_Uniformity=<5;10>} => {Class=malignant} sup: 0.03 conf: 1.00 len: 3, id: 4265,\n",
       "  CAR {Cell_Shape_Uniformity=<3;7>,Marginal_Adhesion=<1;4>,Mitoses=<2;4>} => {Class=malignant} sup: 0.03 conf: 1.00 len: 4, id: 4048,\n",
       "  CAR {Bland_Chromatin=<4;9>,Clump_Thickness=<7;10>,Marginal_Adhesion=<1;2>} => {Class=malignant} sup: 0.03 conf: 1.00 len: 4, id: 7163,\n",
       "  CAR {Clump_Thickness=<7;10>,Mitoses=<2;10>,Single_Epi_Cell_Size=<2;3>} => {Class=malignant} sup: 0.03 conf: 1.00 len: 4, id: 2575,\n",
       "  CAR {Bare_Nuclei=<1.0;3.0>,Marginal_Adhesion=<4;10>,Single_Epi_Cell_Size=<4;10>} => {Class=malignant} sup: 0.03 conf: 1.00 len: 4, id: 7476,\n",
       "  CAR {Cell_Shape_Uniformity=<5;10>,Marginal_Adhesion=<2;6>,Normal_Nucleoli=<1;1>} => {Class=malignant} sup: 0.03 conf: 1.00 len: 4, id: 4971,\n",
       "  CAR {Bland_Chromatin=<4;7>,Clump_Thickness=<5;10>,Single_Epi_Cell_Size=<2;2>} => {Class=malignant} sup: 0.02 conf: 1.00 len: 4, id: 7165,\n",
       "  CAR {Bland_Chromatin=<4;7>,Cell_Shape_Uniformity=<3;6>,Marginal_Adhesion=<1;1>} => {Class=malignant} sup: 0.02 conf: 1.00 len: 4, id: 4314,\n",
       "  CAR {Marginal_Adhesion=<4;10>,Normal_Nucleoli=<3;8>,Single_Epi_Cell_Size=<2;2>} => {Class=malignant} sup: 0.01 conf: 1.00 len: 4, id: 6051],\n",
       " 'benign')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyarc.qcba.transformation import QCBATransformation\n",
    "\n",
    "dataset_name = \"breast-w\"\n",
    "dataset_index = 1\n",
    "\n",
    "\n",
    "\n",
    "train_path_undiscr = [ \"C:/code/python/machine_learning/assoc_rules/folds_undiscr/train/{}{}.csv\".format(dataset_name, dataset_index) for dataset_index in range(0, 9)] \n",
    "test_path_undiscr = [ \"C:/code/python/machine_learning/assoc_rules/folds_undiscr/test/{}{}.csv\".format(dataset_name, dataset_index) for dataset_index in range(0, 9)]\n",
    "\n",
    "train_path_discr = [ \"C:/code/python/machine_learning/assoc_rules/train/{}{}.csv\".format(dataset_name, dataset_index) for dataset_index in range(0, 9)]\n",
    "test_path_discr = [ \"C:/code/python/machine_learning/assoc_rules/test/{}{}.csv\".format(dataset_name, dataset_index) for dataset_index in range(0, 9)]\n",
    "\n",
    "dataset_train_undiscr = pd.concat([ pd.read_csv(ds) for ds in train_path_undiscr ])\n",
    "dataset_test_undiscr = pd.concat([ pd.read_csv(ds) for ds in test_path_undiscr ])\n",
    "dataset_test_undiscr_Y = dataset_test_undiscr.iloc[:,-1]\n",
    "\n",
    "quant_dataset_train = QuantitativeDataFrame(dataset_train_undiscr)\n",
    "quant_dataset_test = QuantitativeDataFrame(dataset_test_undiscr)\n",
    "\n",
    "txns_train_discr = TransactionDB.from_DataFrame(pd.concat([pd.read_csv(ds) for ds in train_path_discr]))\n",
    "txns_test_discr = TransactionDB.from_DataFrame(pd.concat([pd.read_csv(ds) for ds in test_path_discr]))\n",
    "\n",
    "rm_cba = CBA(algorithm=\"m1\", confidence=0.1, support=0.01).fit(txns_train_discr)\n",
    "\n",
    "cba_rule_model = rm_cba\n",
    "quantitative_dataset = quant_dataset\n",
    "\n",
    "__quant_rules = [ QuantitativeCAR(r) for r in cba_rule_model.clf.rules ] \n",
    "\n",
    "qcba_transformation = QCBATransformation(quant_dataset_train)\n",
    "\n",
    "qcba_transformation.transform(__quant_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_extender = RuleExtender1(quant_dataset_train, min_conditional_improvement=-0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_rules = __quant_rules\n",
    "\n",
    "\n",
    "refitted = qcba_transformation.refitter.transform(quant_rules)\n",
    "literal_pruned = qcba_transformation.literal_pruner.transform(refitted)\n",
    "trimmed = qcba_transformation.trimmer.transform(literal_pruned)\n",
    "%timeit extended = qcba_transformation.extender.transform(trimmed)\n",
    "%timeit extended = rule_extender.transform_greedy(trimmed, skip_ahead=10)\n",
    "post_pruned, default_class = qcba_transformation.post_pruner.transform(extended)\n",
    "overlap_pruned = qcba_transformation.overlap_pruner.transform(post_pruned, default_class)\n",
    "\n",
    "\n",
    "clf = QuantitativeClassifier(overlap_pruned, default_class)\n",
    "\n",
    "clf.rule_model_accuracy(quant_dataset_test, dataset_test_undiscr_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running apriori with setting: confidence=0.5, support=0.0, minlen=2, maxlen=3, MAX_RULE_LEN=10\n",
      "Rule count: 702, Iteration: 1\n",
      "Increasing maxlen 4\n",
      "Running apriori with setting: confidence=0.5, support=0.0, minlen=2, maxlen=4, MAX_RULE_LEN=10\n",
      "Rule count: 4185, Iteration: 2\n",
      "Target rule count satisfied: 1000\n",
      "len(rules) 1000\n",
      "applying selected transformations\n",
      "refitting\n",
      "literal pruning\n",
      "trimming\n",
      "extending\n",
      "[                                                  ]\n",
      "[#                                                 ]\n",
      "[##                                                ]\n",
      "[###                                               ]\n",
      "[####                                              ]\n",
      "[#####                                             ]\n",
      "[######                                            ]\n",
      "[#######                                           ]\n",
      "[########                                          ]\n",
      "[#########                                         ]\n",
      "[##########                                        ]\n",
      "[###########                                       ]\n",
      "[############                                      ]\n",
      "[#############                                     ]\n",
      "[##############                                    ]\n",
      "[###############                                   ]\n",
      "[################                                  ]\n",
      "[#################                                 ]\n",
      "[##################                                ]\n",
      "[###################                               ]\n",
      "[####################                              ]\n",
      "[#####################                             ]\n",
      "[######################                            ]\n",
      "[#######################                           ]\n",
      "[########################                          ]\n",
      "[#########################                         ]\n",
      "[##########################                        ]\n",
      "[###########################                       ]\n",
      "[############################                      ]\n",
      "[#############################                     ]\n",
      "[##############################                    ]\n",
      "[###############################                   ]\n",
      "[################################                  ]\n",
      "[#################################                 ]\n",
      "[##################################                ]\n",
      "[###################################               ]\n",
      "[####################################              ]\n",
      "[#####################################             ]\n",
      "[######################################            ]\n",
      "[#######################################           ]\n",
      "[########################################          ]\n",
      "[#########################################         ]\n",
      "[##########################################        ]\n",
      "[###########################################       ]\n",
      "[############################################      ]\n",
      "[#############################################     ]\n",
      "[##############################################    ]\n",
      "[###############################################   ]\n",
      "[################################################  ]\n",
      "[################################################# ]\n",
      "post pruning\n",
      "overlap pruning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9577464788732394"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetname = \"breast-w0\"\n",
    "directory = \"c:/code/python/machine_learning/assoc_rules\"\n",
    "\n",
    "pd_ds = pd.read_csv(\"c:/code/python/machine_learning/assoc_rules/train/{}.csv\".format(datasetname))\n",
    "\n",
    "\n",
    "pd_ds_undiscr = pd.read_csv(\"c:/code/python/machine_learning/assoc_rules/folds_undiscr/train/{}.csv\".format(datasetname))\n",
    "pd_ds_undiscr_test = pd.read_csv(\"c:/code/python/machine_learning/assoc_rules/folds_undiscr/test/{}.csv\".format(datasetname))\n",
    "\n",
    "txns = TransactionDB.from_DataFrame(pd_ds)\n",
    "txns_test = TransactionDB.from_DataFrame(pd.read_csv(\"c:/code/python/machine_learning/assoc_rules/test/{}.csv\".format(datasetname)))\n",
    "\n",
    "\n",
    "rules = top_rules(txns.string_representation, appearance=txns.appeardict)\n",
    "\n",
    "rules.sort(reverse=True)\n",
    "\n",
    "\n",
    "cars = createCARs(rules)\n",
    "\n",
    "cars.sort(reverse=True)\n",
    "\n",
    "if len(cars) > 1000:\n",
    "    cars = cars[:1000]\n",
    "\n",
    "\n",
    "print(\"len(rules)\", len(cars))\n",
    "\n",
    "m1 = M1Algorithm(cars, txns)\n",
    "\n",
    "m1clf = m1.build()\n",
    "\n",
    "rm_cba = CBA()\n",
    "rm_cba.clf = m1clf\n",
    "\n",
    "quant_dataframe = QuantitativeDataFrame(pd_ds_undiscr)\n",
    "\n",
    "rm_qcba = QCBA(rm_cba, quant_dataframe)\n",
    "qcba_clf = rm_qcba.fit()\n",
    "\n",
    "\n",
    "acc_qcba = qcba_clf.rule_model_accuracy(QuantitativeDataFrame(pd_ds_undiscr_test), pd_ds_undiscr_test.iloc[:,-1])\n",
    "\n",
    "acc_qcba"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
