{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ../../../main.py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from pyarc.algorithms import M1Algorithm, M2Algorithm, top_rules, createCARs \n",
    "from pyarc.data_structures import TransactionDB\n",
    "\n",
    "\n",
    "import pyarc.qcba as qcba\n",
    "from pyarc import CBA\n",
    "from pyarc.qcba.data_structures import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyarc.qcba import QCBA\n",
    "\n",
    "import pandas as pd\n",
    "from pyarc.qcba.data_structures import (\n",
    "    IntervalReader,\n",
    "    Interval,\n",
    "    QuantitativeDataFrame,\n",
    "    QuantitativeCAR\n",
    ")\n",
    "\n",
    "interval_reader = IntervalReader()\n",
    "\n",
    "interval_reader.closed_bracket = \"\", \"NULL\"\n",
    "interval_reader.open_bracket = \"NULL\", \"\"\n",
    "interval_reader.infinity_symbol = \"inf\", \"inf\"\n",
    "interval_reader.members_separator = \"_to_\"\n",
    "\n",
    "interval_reader.compile_reader()\n",
    "\n",
    "i = interval_reader.read(\"82.9815_to_inf\")\n",
    "\n",
    "QuantitativeCAR.interval_reader = interval_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running apriori with setting: confidence=0.5, support=0.0, minlen=2, maxlen=3, MAX_RULE_LEN=19\n",
      "Rule count: 40504, Iteration: 1\n",
      "Target rule count satisfied: 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9615384615384616"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyarc import CBA, TransactionDB\n",
    "\n",
    "data_train = pd.read_csv(\"c:/code/python/machine_learning/assoc_rules/train/lymph0.csv\")\n",
    "data_test = pd.read_csv(\"c:/code/python/machine_learning/assoc_rules/test/lymph0.csv\")\n",
    "\n",
    "txns_train = TransactionDB.from_DataFrame(data_train)\n",
    "txns_test = TransactionDB.from_DataFrame(data_train)\n",
    "\n",
    "\n",
    "# get the best association rules\n",
    "rules = top_rules(txns_train.string_representation)\n",
    "\n",
    "# convert them to class association rules\n",
    "cars = createCARs(rules)\n",
    "\n",
    "classifier = M1Algorithm(cars, txns_train).build()\n",
    "\n",
    "accuracy = classifier.test_transactions(txns_test)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"c:/code/python/machine_learning/assoc_rules\"\n",
    "\n",
    "def func(datasetname, unique_transactions=True):\n",
    "    pd_ds = pd.read_csv(\"c:/code/python/machine_learning/assoc_rules/train/{}.csv\".format(datasetname))\n",
    "    \n",
    "    \n",
    "    pd_ds_undiscr = pd.read_csv(\"c:/code/python/machine_learning/assoc_rules/folds_undiscr/train/{}.csv\".format(datasetname))\n",
    "    pd_ds_undiscr_test = pd.read_csv(\"c:/code/python/machine_learning/assoc_rules/folds_undiscr/test/{}.csv\".format(datasetname))\n",
    "    \n",
    "    txns = TransactionDB.from_DataFrame(pd_ds, unique_transactions=unique_transactions)\n",
    "    txns_test = TransactionDB.from_DataFrame(pd.read_csv(\"c:/code/python/machine_learning/assoc_rules/test/{}.csv\".format(datasetname)))\n",
    "\n",
    "    \n",
    "    rules = top_rules(txns.string_representation, appearance=txns.appeardict)\n",
    "\n",
    "    rules.sort(reverse=True)\n",
    "\n",
    "\n",
    "    cars = createCARs(rules)\n",
    "\n",
    "    cars.sort(reverse=True)\n",
    "\n",
    "    if len(cars) > 1000:\n",
    "        cars = cars[:1000]\n",
    "        \n",
    "\n",
    "    print(\"len(rules)\", len(cars))\n",
    "\n",
    "    m1 = M1Algorithm(cars, txns)\n",
    "    \n",
    "    m2 = M2Algorithm(cars, txns)\n",
    "    \n",
    "    m1clf = m1.build()\n",
    "    m2clf = m2.build()\n",
    "    \n",
    "    rm_cba = CBA()\n",
    "    rm_cba.clf = m1clf\n",
    "    \n",
    "    quant_dataframe = QuantitativeDataFrame(pd_ds_undiscr)\n",
    "    \n",
    "    rm_qcba = QCBA(rm_cba, quant_dataframe)\n",
    "    qcba_clf = rm_qcba.fit()\n",
    "    \n",
    "    actual = list(map(lambda i: i.value, txns_test.class_labels))\n",
    "\n",
    "    pred = m1clf.predict_all(txns_test)\n",
    "    predM2 = m2clf.predict_all(txns_test)\n",
    "    \n",
    "    accM2 = accuracy_score(predM2, actual)\n",
    "    acc = accuracy_score(pred, actual)\n",
    "    acc_qcba = qcba_clf.rule_model_accuracy(QuantitativeDataFrame(pd_ds_undiscr_test), pd_ds_undiscr_test.iloc[:,-1])\n",
    "\n",
    "    return acc, accM2, acc_qcba\n",
    "\n",
    "\n",
    "\n",
    "def mean_func(dataset_name, start=0, end=10, unique_transactions=True):\n",
    "    files = [ dataset_name + repr(i) for i in range(start, end) ]\n",
    "\n",
    "    accs = []\n",
    "    accsM2 = []\n",
    "    accs_qcba = []\n",
    "    \n",
    "    for file in files:\n",
    "        acc, accM2, acc_qcba = func(file, unique_transactions=unique_transactions)\n",
    "        print(\"done\", file, acc)\n",
    "        print(\"done m2\", file, accM2)\n",
    "        print(\"done qcba\", file, acc_qcba)\n",
    "        accs.append(acc)\n",
    "        accsM2.append(accM2)\n",
    "        accs_qcba.append(acc_qcba)\n",
    "        \n",
    "    mn = sum(accs) / len(accs)\n",
    "    mnM2 = sum(accsM2) / len(accsM2)\n",
    "    mn_qcba = sum(accs_qcba) / len(accs_qcba)\n",
    "    \n",
    "    return mn, mnM2, mn_qcba\n",
    "\n",
    "\n",
    "                \n",
    "datasets = [\n",
    "    \"iris\",\n",
    "    \"breast-w\",\n",
    "    \"anneal\",\n",
    "    \"hypothyroid\",\n",
    "    \"ionosphere\",\n",
    "    \"lymph\",\n",
    "    \"vehicle\",\n",
    "    \"autos\",\n",
    "    \"diabetes\",\n",
    "    \"glass\",\n",
    "    \"heart-h\",\n",
    "    \"tic-tac-toe\",\n",
    "    \"australian\",\n",
    "    \"sick\",\n",
    "    \"segment\",\n",
    "    \"spambase\",\n",
    "    \"sonar\",\n",
    "    \"vowel\",\n",
    "    \"hepatitis\",\n",
    "    \"credit-a\",\n",
    "    \"mushroom\",\n",
    "    \"house-votes-84\",\n",
    "    \"soybean\",\n",
    "    \"primary-tumor\",\n",
    "    \"credit-g\",\n",
    "    \"audiology\",\n",
    "    \"breast-cancer\",\n",
    "    \"balance-scale\",\n",
    "    \"heart-c\",\n",
    "    \"kr-vs-kp\",\n",
    "    \"pima\",\n",
    "    \"heart-statlog\"]    \n",
    "\n",
    "means = []\n",
    "meansM2 = []\n",
    "means_qcba = []\n",
    "for dataset in [\"audiology\"]:\n",
    "    acc, accM2, acc_qcba = mean_func(dataset)\n",
    "    print(\"*****\")\n",
    "    print(\"M1\", dataset, acc)\n",
    "    print(\"M2\", dataset, accM2)\n",
    "    print(\"******\")\n",
    "    \n",
    "    means.append((dataset, acc))\n",
    "    meansM2.append((dataset, accM2))\n",
    "    means_qcba.append((dataset, acc_qcba))\n",
    "    \n",
    "print(\"M1\")\n",
    "print(means)\n",
    "print(\"\\nM2\")\n",
    "print(meansM2)\n",
    "print(\"\\nQCBA\")\n",
    "print(means_qcba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
